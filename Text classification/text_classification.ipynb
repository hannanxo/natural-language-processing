{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c913cce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Abdul\n",
      "[nltk_data]     Hannan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk \n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swnet\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb302b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Label</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Movies_TV</td>\n",
       "      <td>POS</td>\n",
       "      <td>5</td>\n",
       "      <td>my boy love this film . sometime my youngest g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movies_TV</td>\n",
       "      <td>NEU</td>\n",
       "      <td>3</td>\n",
       "      <td>on my disk the last scene of episode 2 : New E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Movies_TV</td>\n",
       "      <td>POS</td>\n",
       "      <td>4</td>\n",
       "      <td>I have a 4yr old son and he love this cartoon ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Movies_TV</td>\n",
       "      <td>POS</td>\n",
       "      <td>5</td>\n",
       "      <td>this sequal be wonderful . the animation be ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Movies_TV</td>\n",
       "      <td>POS</td>\n",
       "      <td>5</td>\n",
       "      <td>I really hope sci-fi never take off the doctor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Domain Label  Rating                                             Review\n",
       "0  Movies_TV   POS       5  my boy love this film . sometime my youngest g...\n",
       "1  Movies_TV   NEU       3  on my disk the last scene of episode 2 : New E...\n",
       "2  Movies_TV   POS       4  I have a 4yr old son and he love this cartoon ...\n",
       "3  Movies_TV   POS       5  this sequal be wonderful . the animation be ex...\n",
       "4  Movies_TV   POS       5  I really hope sci-fi never take off the doctor..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Movies_TV.txt', delimiter = '\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "610ed829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48c44c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering the data-set\n",
    "df = df.replace('[\"\"-:!\",?.\\n()]', '', regex=True)\n",
    "df = df.replace(\"\"\"[\"`']\"\"\", '', regex=True)\n",
    "df['Review'] = df['Review'].str.lower()\n",
    "df['Review'] = df['Review'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dfcd3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the stopwords from the data-set so that we only get useful associations among words\n",
    "df['Review'] = df['Review'].apply(lambda words: ' '.join([word for word in words.split() if word not in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0208e813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    boy love film sometime youngest get scared cap...\n",
       "1    disk last scene episode new earth miss instead...\n",
       "2         yr old son love cartoon buy story intresting\n",
       "3    sequal wonderful animation excellent though ma...\n",
       "4    really hope scifi never take doctor best show ...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed8dc26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['Review'], df['Rating'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f087c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb23ae18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c530fb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703    relevance film strikingly frightening today un...\n",
       "311    fly fly fly imagination take far away land nev...\n",
       "722    well box claim get magic wonder suspense origi...\n",
       "629    watch dr since tom baker show david tennent ar...\n",
       "0      boy love film sometime youngest get scared cap...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2fe695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using sentiwordnet to classify "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6235100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a function that takes reviews as input and for every word in review\n",
    "#it finds its positive and negative score. Keep count of all the positive, negative\n",
    "#and neutral words so we can compute the rating using them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce800fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_reviews = x_train.size\n",
    "synset1 = wn.synsets('positive')[0]\n",
    "synset2 = wn.synsets('negative')[0]\n",
    "def classifier():\n",
    "    correctClassified = 0\n",
    "    false_pos = 0\n",
    "    for i in range(total_reviews):\n",
    "        pos = neg = neut = 0\n",
    "        review = df.iloc[i]['Review']\n",
    "        review_size = 0\n",
    "        tokenList = word_tokenize(''.join(review))\n",
    "#         print(review)\n",
    "        \n",
    "        for token in tokenList:\n",
    "            rating = 5 \n",
    "            if not(wn.synsets(token)):\n",
    "                continue\n",
    "                \n",
    "            word = wn.synsets(token)[0]\n",
    "            synset = swnet.senti_synset(word.name())\n",
    "            posDistance = synset.pos_score()\n",
    "            negDistance = synset.neg_score()\n",
    "            review_size = review_size + 1 \n",
    "            \n",
    "            if(posDistance > negDistance):\n",
    "                pos = pos + 1\n",
    "            elif(negDistance > posDistance):\n",
    "                neg = neg + 1\n",
    "            elif(posDistance == 0 and negDistance == 0):\n",
    "                pos = pos + 1 # for neutral\n",
    "                \n",
    "#         print('Size', review_size)\n",
    "#         print('+ve', pos)\n",
    "#         print('-ve', neg)\n",
    "        \n",
    "        if(pos > neg):\n",
    "            percentage = math.floor((neg / 100) * review_size)\n",
    "#             percentage = math.ceil(neg / review_size)\n",
    "            if(percentage > rating):\n",
    "                percentage = percentage / pos\n",
    "            deduct = math.floor(rating - percentage)\n",
    "            updated_rating = deduct\n",
    "           \n",
    "            \n",
    "        if(neg == 0):\n",
    "            updated_rating = rating\n",
    "        \n",
    "        if(updated_rating == y_train.iloc[i]):\n",
    "            correctClassified = correctClassified + 1\n",
    "        else:\n",
    "            false_pos = false_pos + 1\n",
    "            \n",
    "#         print('Actual Rating', y_train.iloc[i])\n",
    "#         print('Rating', updated_rating)\n",
    "        tokenList = ''\n",
    "#         print(\"..........\")\n",
    "#     print('Corrected',correctClassified)\n",
    "    print(\"Accuracy : \", (correctClassified / total_reviews * 1.0))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "126463f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.4059701492537313\n"
     ]
    }
   ],
   "source": [
    "classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a303ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20234d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data\n",
    "data = open(\"Movies_TV.txt\").read()\n",
    "data = data.split('\\n')\n",
    "data.remove(data[0])\n",
    "data.remove(data[-1])\n",
    "data.remove(data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b53f10e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "y = []\n",
    "for item in data:\n",
    "    _, _, rating, text = item.split('\\t')\n",
    "    reviews.append(text)\n",
    "    y.append(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d9e63821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec = TfidfVectorizer(max_df = 600, min_df = 5, ngram_range = (1,3), max_features = 80)\n",
    "X = vec.fit_transform(reviews)\n",
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cba078ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ac579326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainX, testX, trainY, testY = train_test_split(X, y, shuffle = True, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "615eb27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5a99407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = SGDClassifier()\n",
    "nbc = GaussianNB()\n",
    "dtc = DecisionTreeClassifier()\n",
    "knnc = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ece07666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc.fit(trainX, trainY)\n",
    "nbc.fit(trainX, trainY)\n",
    "dtc.fit(trainX, trainY)\n",
    "knnc.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e26760df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_lc = lc.predict(testX)\n",
    "pred_y_nbc = nbc.predict(testX)\n",
    "pred_y_dtc = dtc.predict(testX)\n",
    "pred_y_knnc = knnc.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "58a7c90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "lc_acc = accuracy_score(testY, pred_y_lc)\n",
    "nbc_acc = accuracy_score(testY, pred_y_nbc)\n",
    "dtc_acc = accuracy_score(testY, pred_y_dtc)\n",
    "knnc_acc = accuracy_score(testY, pred_y_knnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "36a4e13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Classifier:  0.64\n",
      "Naive Bayes Classifier:  0.43333333333333335\n",
      "Decision Tree Classifier:  0.53\n",
      "KNN Classifier:  0.62\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Classifier: \", lc_acc)\n",
    "print(\"Naive Bayes Classifier: \", nbc_acc)\n",
    "print(\"Decision Tree Classifier: \", dtc_acc)\n",
    "print(\"KNN Classifier: \", knnc_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b711ed83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Linear Classifier\n",
      ".....................\n",
      "Macro\n",
      "Percision, recall, f1-score (0.35210112710112706, 0.2900998199967272, 0.30221033868092695, None)\n",
      "Micro\n",
      "Percision, recall, f1-score (0.64, 0.64, 0.64, None)\n",
      "Weighted\n",
      "Percision, recall, f1-score (0.6109778284778284, 0.64, 0.611306357694593, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "Macro=precision_recall_fscore_support(testY, pred_y_lc, average='macro')\n",
    "Micro=precision_recall_fscore_support(testY,pred_y_lc, average='micro')\n",
    "Weighted=precision_recall_fscore_support(testY,pred_y_lc, average='weighted')\n",
    "\n",
    "print(\"Classification Report for Linear Classifier\")\n",
    "print('.....................')\n",
    "print('Macro')\n",
    "print('Percision, recall, f1-score', Macro)\n",
    "print('Micro')\n",
    "print('Percision, recall, f1-score', Micro)\n",
    "print('Weighted')\n",
    "print('Percision, recall, f1-score', Weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "63f226e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Naive Bayes\n",
      ".....................\n",
      "Macro\n",
      "Percision, recall, f1-score (0.3040588130405064, 0.38309687448862706, 0.2967875381708436, None)\n",
      "Micro\n",
      "Percision, recall, f1-score (0.43333333333333335, 0.43333333333333335, 0.43333333333333335, None)\n",
      "Weighted\n",
      "Percision, recall, f1-score (0.6175245549644863, 0.43333333333333335, 0.48711419968693936, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "Macro=precision_recall_fscore_support(testY, pred_y_nbc, average='macro')\n",
    "Micro=precision_recall_fscore_support(testY,pred_y_nbc, average='micro')\n",
    "Weighted=precision_recall_fscore_support(testY,pred_y_nbc, average='weighted')\n",
    "\n",
    "print(\"Classification Report for Naive Bayes\")\n",
    "print('.....................')\n",
    "print('Macro')\n",
    "print('Percision, recall, f1-score', Macro)\n",
    "print('Micro')\n",
    "print('Percision, recall, f1-score', Micro)\n",
    "print('Weighted')\n",
    "print('Percision, recall, f1-score', Weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "437a9622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Decision Tree\n",
      ".....................\n",
      "Macro\n",
      "Percision, recall, f1-score (0.2789665398091835, 0.27409998363606614, 0.27546768581909253, None)\n",
      "Micro\n",
      "Percision, recall, f1-score (0.53, 0.53, 0.53, None)\n",
      "Weighted\n",
      "Percision, recall, f1-score (0.5430537165979352, 0.53, 0.5359209946843667, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "Macro=precision_recall_fscore_support(testY, pred_y_dtc, average='macro')\n",
    "Micro=precision_recall_fscore_support(testY,pred_y_dtc, average='micro')\n",
    "Weighted=precision_recall_fscore_support(testY,pred_y_dtc, average='weighted')\n",
    "\n",
    "print(\"Classification Report for Decision Tree\")\n",
    "print('.....................')\n",
    "print('Macro')\n",
    "print('Percision, recall, f1-score', Macro)\n",
    "print('Micro')\n",
    "print('Percision, recall, f1-score', Micro)\n",
    "print('Weighted')\n",
    "print('Percision, recall, f1-score', Weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7b79a683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for KNN\n",
      ".....................\n",
      "Macro\n",
      "Percision, recall, f1-score (0.3140146381133098, 0.2808991981672394, 0.2865009882198486, None)\n",
      "Micro\n",
      "Percision, recall, f1-score (0.62, 0.62, 0.62, None)\n",
      "Weighted\n",
      "Percision, recall, f1-score (0.5931571338212704, 0.62, 0.6003479818196088, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "Macro=precision_recall_fscore_support(testY, pred_y_knnc, average='macro')\n",
    "Micro=precision_recall_fscore_support(testY,pred_y_knnc, average='micro')\n",
    "Weighted=precision_recall_fscore_support(testY,pred_y_knnc, average='weighted')\n",
    "\n",
    "print(\"Classification Report for KNN\")\n",
    "print('.....................')\n",
    "print('Macro')\n",
    "print('Percision, recall, f1-score', Macro)\n",
    "print('Micro')\n",
    "print('Percision, recall, f1-score', Micro)\n",
    "print('Weighted')\n",
    "print('Percision, recall, f1-score', Weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa3c555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
